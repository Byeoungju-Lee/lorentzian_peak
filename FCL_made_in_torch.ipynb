{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Library 예시\n",
    "\n",
    "import math\n",
    "import time\n",
    "from itertools import chain\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "# 모델 학습을 위해 CUDA 환경 설정. : 지피유 설정\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available else 'cpu')\n",
    "#device=torch.device('cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=np.linspace(1000,2000,51)\n",
    "w=np.linspace(2300,8000,20)\n",
    "wavenumbers=np.append(u,w)\n",
    "len(wavenumbers)\n",
    "wavenumbers=np.linspace(1000, 8000, 71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset=>train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4824600, 215)\n",
      "train file saved....\n"
     ]
    }
   ],
   "source": [
    "# 별도의 데이터 Pre-Processing 과정은 없고 모델 훈련시 검증을 위해 train 중 10000개를 validation 용으로 분리.\n",
    "# 새로 만든 train.csv는 train1.csv, validation은 val.csv로 저장.\n",
    "# dataframe.sample(frac=1) 을 통해 셔플.\n",
    "path_train = 'train_same_layer_level_4per.csv'\n",
    "#path_test = 'test.csv'\n",
    "layers = [[str(i) for i in wavenumbers.tolist()],[str(i) for i in wavenumbers.tolist()],['layer(nm)','level(%)'], [str(i) for i in np.arange(1000,8100,100).tolist()]]\n",
    "layers = list(chain(*layers))\n",
    "\n",
    "train = pd.read_csv(path_train)\n",
    "print(train.shape)\n",
    "train = train.sample(frac=1)\n",
    "rows, cols = train.shape\n",
    "\n",
    "train1 = train.iloc[:rows - (int(0.1*len(train))),:]\n",
    "train1 = train1.values\n",
    "train1 = pd.DataFrame(data=train1,columns=layers)\n",
    "train1.to_csv('train1_same_layer_level.csv', index_label='id')\n",
    "\n",
    "print(\"train file saved....\")\n",
    "val = train.iloc[rows - (int(0.1*len(train))):,:]\n",
    "val = val.values\n",
    "val = pd.DataFrame(data=val,columns=layers)\n",
    "val.to_csv('val_same_layer_level.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로 만든 train/ val 모델 학습 데이터 경로를 설정.\n",
    "train_path = 'train1_same_layer_level.csv'#레이어를 같게 두고 풀때\n",
    "val_path = 'val_same_layer_level.csv'\n",
    "\n",
    "lr = 1e-03\n",
    "adam_epsilon = 1e-06\n",
    "epochs = 100 #12-17: 200->100\n",
    "batch_size = 2048\n",
    "warmup_step = 2000\n",
    "\n",
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super(PandasDataset, self).__init__()\n",
    "        train = pd.read_csv(path).iloc[:,1:]\n",
    "        self.train_X, self.train_Y = train.iloc[:,144:], train.iloc[:,0:144]\n",
    "        self.tmp_x , self.tmp_y = self.train_X.values, self.train_Y.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'X':torch.from_numpy(self.tmp_x)[idx],\n",
    "            'Y':torch.from_numpy(self.tmp_y)[idx]\n",
    "        }\n",
    "            \n",
    "train_dataset = PandasDataset(train_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, pin_memory=True, num_workers=0)#card에 data size/batch size만큼 monunt\n",
    "\n",
    "val_dataset = PandasDataset(val_path)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, pin_memory=True,  num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #input: 71X1\n",
    "        self.conv1=nn.Sequential(nn.Conv1d(1,32,kernel_size=3, stride=2 , padding=1),nn.BatchNorm1d(32),nn.ReLU(),nn.MaxPool1d(1, stride=1, padding=0))\n",
    "        #36x32: 32-channel 개수\n",
    "        self.conv2=nn.Sequential(nn.Conv1d(32,64,kernel_size=1,stride=1,padding=0),nn.BatchNorm1d(64),nn.ReLU(),nn.MaxPool1d(1, stride=1))\n",
    "        #36X64\n",
    "        self.conv3=nn.Sequential(nn.Conv1d(64,128,kernel_size=1,stride=1,padding=0),nn.BatchNorm1d(128),nn.ReLU(),nn.MaxPool1d(1, stride=1))\n",
    "        #36x128\n",
    "        self.conv4=nn.Sequential(nn.Conv1d(128,128,kernel_size=1,stride=1,padding=0),nn.BatchNorm1d(128),nn.ReLU(),nn.MaxPool1d(1, stride=1))\n",
    "        #36x128\n",
    "        self.conv5=nn.Sequential(nn.Conv1d(128,64,kernel_size=1,stride=1,padding=0),nn.BatchNorm1d(64),nn.ReLU(),nn.MaxPool1d(1, stride=1))\n",
    "        #36x64\n",
    "        self.conv6=nn.Sequential(nn.Conv1d(64,32,kernel_size=1,stride=1,padding=0),nn.BatchNorm1d(32),nn.ReLU(),nn.MaxPool1d(1, stride=1))\n",
    "        #36X32\n",
    "        self.fconv1=nn.Sequential(nn.Conv1d(32,32,kernel_size=2,stride=2,padding=0),nn.BatchNorm1d(32),nn.ReLU(),nn.MaxPool1d(1, stride=1))\n",
    "        #18x32\n",
    "        self.fc1=nn.Sequential(nn.Linear(18*32, 144, bias=True), nn.BatchNorm1d(144)) #nk out\n",
    "        #Add layer to fit thick\n",
    "        self.layer1=nn.Sequential(nn.Linear(18*32,2000), nn.BatchNorm1d(2000), nn.ReLU())\n",
    "        #2000\n",
    "        self.layer2=nn.Sequential(nn.Linear(2000,4000),nn.BatchNorm1d(4000), nn.ReLU())\n",
    "        #4000\n",
    "        self.layer3=nn.Sequential(nn.Linear(4000,2000), nn.BatchNorm1d(2000), nn.ReLU())\n",
    "        #2000\n",
    "        self.layer4=nn.Sequential(nn.Linear(2000,300), nn.BatchNorm1d(300), nn.ReLU())\n",
    "        #thick and level\n",
    "        self.fc2=nn.Sequential(nn.Linear(300,2)) #thickness, level out\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(x.shape) batch size X columns \n",
    "        x=x.view(x.shape[0],1,-1)\n",
    "#         print(x.shape) batch size X 1 X columns \n",
    "        upout1 = self.conv1(x) #batch size X 36 X 32\n",
    "        \n",
    "        upout2 = self.conv2(upout1) #36x64\n",
    "        #print(out.shape)\n",
    "        upout3 = self.conv3(upout2) #36x128\n",
    "        \n",
    "        downout3=self.conv4(upout3) #36x128\n",
    "        \n",
    "        downout2=self.conv5(downout3+upout3)#36x64\n",
    "        \n",
    "        downout1=self.conv6(downout2+upout2) #36x32\n",
    "        \n",
    "        fout=self.fconv1(downout1+upout1) #18x32\n",
    "        #print(fout.shape)\n",
    "        \n",
    "        out=fout.view(x.shape[0], fout.size(1)*fout.size(2))\n",
    "        #thickness\n",
    "        #thout=self.layer1(out) #2000\n",
    "        #print(out.shape)\n",
    "       # print(thout.shape)\n",
    "        out1=self.fc1(out)\n",
    "        #thickness\n",
    "#         out2=self.layer2(thout)#4000\n",
    "#         out2=self.layer3(out2)\n",
    "#         out2=self.layer4(out2)\n",
    "#         out2=self.fc2(out2)\n",
    "#         print(out1.shape)\n",
    "#         print(out2.shape)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=FCN()\n",
    "model=ConvNet() #ReLU를 뺐더니 이득봄.\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nk_loss_fn=nn.KLDivLoss(reduction='batchmean')\n",
    "thick_loss_fn=nn.L1Loss()\n",
    "level_loss_fn=nn.L1Loss()\n",
    "loss_fn=nn.L1Loss()\n",
    "loss_fn2=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf3f3bb39884de9b7211896973883cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='*********Train mode*******'), FloatProgress(value=0.0, max=2121.0), HTML(value=''))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "torch.Size([2048, 32, 36])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4b878b6e548c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update optimizer params\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mn_k_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_nk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mthick_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_thick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = lr, eps=adam_epsilon)\n",
    "\n",
    "total_loss=0.0\n",
    "n_k_loss=0.0\n",
    "thick_loss=0.0\n",
    "level_loss=0.0\n",
    "total_val_loss=0.0\n",
    "\n",
    "version = time.localtime()[3:5]\n",
    "curr_lr = lr\n",
    "\n",
    "n_val_loss = 10000000. # 가장 낮은 validation loss를 저장하기 위해서 변수 설정.\n",
    "train_loss_epoch=[]\n",
    "nk_loss_epoch=[]\n",
    "thick_loss_epoch=[]\n",
    "level_loss_epoch=[]\n",
    "val_loss_epoch=[]\n",
    "\n",
    "start = time.time() # 학습시간 측정.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss=0.0\n",
    "    n_k_loss=0.0\n",
    "    thick_loss=0.0\n",
    "    level_loss=0.0\n",
    "    total_val_loss=0.0\n",
    "    for i, data in enumerate(tqdm(train_loader, desc='*********Train mode*******')):  # train 데이터를 부르고 학습.\n",
    "        # forward pass\n",
    "        pred1 = model(data['X'].float().to(device))\n",
    "       # print('data[Y].shape: ',data['Y'].shape)\n",
    "       # print('pred1.shape: ',pred1.shape)\n",
    "        loss_nk = loss_fn2(pred1[:,:142], data['Y'].float().to(device)[:,:142])\n",
    "        loss_thick=loss_fn(pred1[:,142], data['Y'].float().to(device)[:,142])\n",
    "        loss_level=loss_fn(pred1[:,143], data['Y'].float().to(device)[:,143])\n",
    "        \n",
    "        loss=torch.sqrt(loss_nk) + loss_thick + loss_level\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad() # optimizer 객체 사용해서 학습 가능한 가중치 변수에 대한 모든 변화도를 0으로 만듦\n",
    "        loss.backward()\n",
    "        optimizer.step() # update optimizer params\n",
    "        \n",
    "        total_loss+=loss.item()\n",
    "        n_k_loss += loss_nk.item()\n",
    "        thick_loss += loss_thick.item()\n",
    "        level_loss += loss_level.item()\n",
    "    \n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_loss_epoch.append(train_loss)\n",
    "    nk_losses= n_k_loss/len(train_loader)\n",
    "    nk_loss_epoch.append(nk_losses)\n",
    "    thick_losses = thick_loss / len(train_loader)\n",
    "    thick_loss_epoch.append(thick_losses)\n",
    "    level_losses = level_loss/len(train_loader)\n",
    "    level_loss_epoch.append(level_losses)\n",
    "    \n",
    "    print (\"Epoch [{}/{}], Train Loss: {:.4f}\".format(epoch+1, epochs, train_loss))\n",
    "    print (\"Epoch [{}/{}], nk Loss: {:.4f}\".format(epoch+1, epochs, nk_losses))\n",
    "    print (\"Epoch [{}/{}], Thick Loss: {:.4f}\".format(epoch+1, epochs, thick_losses))\n",
    "    print(\"Epoch [{}/{}], level Loss: {:.4f}\".format(epoch+1, epochs, level_losses))\n",
    "    print('Train Time: ',time.time()-start)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(val_loader, desc='*********Evaluation mode*******')):\n",
    "            pred1 = model(data['X'].float().to(device))\n",
    "            loss_nk = loss_fn2(pred1[:,:142], data['Y'].float().to(device)[:,:142])\n",
    "            loss_thick=loss_fn(pred1[:,142], data['Y'].float().to(device)[:,142])\n",
    "            loss_level=loss_fn(pred1[:,143], data['Y'].float().to(device)[:,143])\n",
    "        \n",
    "            loss_val=torch.sqrt(loss_nk) + loss_thick + loss_level\n",
    "            total_val_loss += loss_val.item()\n",
    "            \n",
    "    val_loss = total_val_loss / len(val_loader)\n",
    "    val_loss_epoch.append(val_loss)\n",
    "    print (\"Epoch [{}/{}], Eval Loss: {:.4f}\".format(epoch+1, epochs, val_loss))\n",
    "    \n",
    "    #Save best model\n",
    "    if val_loss < n_val_loss:\n",
    "        n_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'test_percent_unit_{version}_{lr}_{epochs}_MAE.pth')\n",
    "        print(\"Best Model saved......\")\n",
    "print('Operation over:' ,time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_data=pd.DataFrame(train_loss_epoch)\n",
    "train_loss_data.to_csv(f'weight_upper_train_loss_lr={lr}_epochs={epochs}_Unet.csv')\n",
    "n_k_loss_data=pd.DataFrame(nk_loss_epoch)\n",
    "n_k_loss_data.to_csv(f'weight_upper_n_k_loss_lr={lr}_epochs={epochs}_Unet.csv')\n",
    "thick_loss_data=pd.DataFrame(thick_loss_epoch)\n",
    "thick_loss_data.to_csv(f'weight_upper_thick_loss_lr={lr}_epochs={epochs}_Unet.csv')\n",
    "level_loss_data=pd.DataFrame(level_loss_epoch)\n",
    "level_loss_data.to_csv(f'weight_upper_level_loss_lr={lr}_epochs={epochs}_Unet.csv')\n",
    "val_loss_data=pd.DataFrame(val_loss_epoch)\n",
    "val_loss_data.to_csv(f'weight_upper_val_loss_lr={lr}_epochs={epochs}_Unet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test_using_pre-trained_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1000</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1060</th>\n",
       "      <th>1080</th>\n",
       "      <th>1100</th>\n",
       "      <th>1120</th>\n",
       "      <th>1140</th>\n",
       "      <th>1160</th>\n",
       "      <th>...</th>\n",
       "      <th>5300</th>\n",
       "      <th>5600</th>\n",
       "      <th>5900</th>\n",
       "      <th>6200</th>\n",
       "      <th>6500</th>\n",
       "      <th>6800</th>\n",
       "      <th>7100</th>\n",
       "      <th>7400</th>\n",
       "      <th>7700</th>\n",
       "      <th>8000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.43274</td>\n",
       "      <td>0.45783</td>\n",
       "      <td>0.52730</td>\n",
       "      <td>0.59830</td>\n",
       "      <td>0.65145</td>\n",
       "      <td>0.67806</td>\n",
       "      <td>0.60875</td>\n",
       "      <td>0.53671</td>\n",
       "      <td>0.51018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12483</td>\n",
       "      <td>0.10819</td>\n",
       "      <td>0.09743</td>\n",
       "      <td>0.08981</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.09001</td>\n",
       "      <td>0.09514</td>\n",
       "      <td>0.10468</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.12928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43904</td>\n",
       "      <td>0.45938</td>\n",
       "      <td>0.52918</td>\n",
       "      <td>0.60372</td>\n",
       "      <td>0.66068</td>\n",
       "      <td>0.69203</td>\n",
       "      <td>0.62289</td>\n",
       "      <td>0.54710</td>\n",
       "      <td>0.51771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12187</td>\n",
       "      <td>0.10667</td>\n",
       "      <td>0.09560</td>\n",
       "      <td>0.08961</td>\n",
       "      <td>0.08885</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.09896</td>\n",
       "      <td>0.10972</td>\n",
       "      <td>0.12254</td>\n",
       "      <td>0.13703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.44766</td>\n",
       "      <td>0.47016</td>\n",
       "      <td>0.53749</td>\n",
       "      <td>0.60886</td>\n",
       "      <td>0.66225</td>\n",
       "      <td>0.68836</td>\n",
       "      <td>0.61643</td>\n",
       "      <td>0.54579</td>\n",
       "      <td>0.51949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12975</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.09679</td>\n",
       "      <td>0.08965</td>\n",
       "      <td>0.08626</td>\n",
       "      <td>0.08614</td>\n",
       "      <td>0.09011</td>\n",
       "      <td>0.09838</td>\n",
       "      <td>0.10924</td>\n",
       "      <td>0.12265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.44381</td>\n",
       "      <td>0.46831</td>\n",
       "      <td>0.53629</td>\n",
       "      <td>0.60635</td>\n",
       "      <td>0.65804</td>\n",
       "      <td>0.68132</td>\n",
       "      <td>0.60812</td>\n",
       "      <td>0.53913</td>\n",
       "      <td>0.51423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13201</td>\n",
       "      <td>0.11226</td>\n",
       "      <td>0.09741</td>\n",
       "      <td>0.09049</td>\n",
       "      <td>0.08637</td>\n",
       "      <td>0.08561</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.10493</td>\n",
       "      <td>0.11727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.45495</td>\n",
       "      <td>0.47851</td>\n",
       "      <td>0.54659</td>\n",
       "      <td>0.61701</td>\n",
       "      <td>0.66936</td>\n",
       "      <td>0.69344</td>\n",
       "      <td>0.62036</td>\n",
       "      <td>0.55081</td>\n",
       "      <td>0.52515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13925</td>\n",
       "      <td>0.11865</td>\n",
       "      <td>0.10473</td>\n",
       "      <td>0.09669</td>\n",
       "      <td>0.09205</td>\n",
       "      <td>0.09209</td>\n",
       "      <td>0.09437</td>\n",
       "      <td>0.10121</td>\n",
       "      <td>0.11054</td>\n",
       "      <td>0.12158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.44943</td>\n",
       "      <td>0.47328</td>\n",
       "      <td>0.54287</td>\n",
       "      <td>0.61628</td>\n",
       "      <td>0.67115</td>\n",
       "      <td>0.69813</td>\n",
       "      <td>0.62540</td>\n",
       "      <td>0.55229</td>\n",
       "      <td>0.52505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12488</td>\n",
       "      <td>0.10616</td>\n",
       "      <td>0.09400</td>\n",
       "      <td>0.08691</td>\n",
       "      <td>0.08540</td>\n",
       "      <td>0.08701</td>\n",
       "      <td>0.09278</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.11422</td>\n",
       "      <td>0.12778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     1000     1020     1040     1060     1080     1100     1120  \\\n",
       "0           0  0.43274  0.45783  0.52730  0.59830  0.65145  0.67806  0.60875   \n",
       "1           1  0.43904  0.45938  0.52918  0.60372  0.66068  0.69203  0.62289   \n",
       "2           2  0.44766  0.47016  0.53749  0.60886  0.66225  0.68836  0.61643   \n",
       "3           3  0.44381  0.46831  0.53629  0.60635  0.65804  0.68132  0.60812   \n",
       "4           4  0.45495  0.47851  0.54659  0.61701  0.66936  0.69344  0.62036   \n",
       "5           5  0.44943  0.47328  0.54287  0.61628  0.67115  0.69813  0.62540   \n",
       "\n",
       "      1140     1160  ...     5300     5600     5900     6200     6500  \\\n",
       "0  0.53671  0.51018  ...  0.12483  0.10819  0.09743  0.08981  0.08758   \n",
       "1  0.54710  0.51771  ...  0.12187  0.10667  0.09560  0.08961  0.08885   \n",
       "2  0.54579  0.51949  ...  0.12975  0.11030  0.09679  0.08965  0.08626   \n",
       "3  0.53913  0.51423  ...  0.13201  0.11226  0.09741  0.09049  0.08637   \n",
       "4  0.55081  0.52515  ...  0.13925  0.11865  0.10473  0.09669  0.09205   \n",
       "5  0.55229  0.52505  ...  0.12488  0.10616  0.09400  0.08691  0.08540   \n",
       "\n",
       "      6800     7100     7400     7700     8000  \n",
       "0  0.09001  0.09514  0.10468  0.11640  0.12928  \n",
       "1  0.09206  0.09896  0.10972  0.12254  0.13703  \n",
       "2  0.08614  0.09011  0.09838  0.10924  0.12265  \n",
       "3  0.08561  0.08862  0.09546  0.10493  0.11727  \n",
       "4  0.09209  0.09437  0.10121  0.11054  0.12158  \n",
       "5  0.08701  0.09278  0.10200  0.11422  0.12778  \n",
       "\n",
       "[6 rows x 72 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file='R_test_weight.xlsx'\n",
    "test=pd.read_excel(test_file)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "모델 테스트\n",
    "\"\"\"\n",
    "\n",
    "test_model = ConvNet()\n",
    "\n",
    "# test 파일 경로 및 test 데이터 로드\n",
    "path_test = 'R_test_weight.xlsx'\n",
    "#path_test='val_same_layer_level.csv'\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path_test):\n",
    "        super(TestDataset, self).__init__()\n",
    "        test = pd.read_excel(path_test)\n",
    "        self.test_X = test.iloc[:,1:]\n",
    "        self.tmp_x = self.test_X.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.tmp_x)[idx]\n",
    "    \n",
    "test_data = TestDataset(path_test)\n",
    "test_loader = DataLoader(test_data, batch_size=6,pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Time :  0.0\n"
     ]
    }
   ],
   "source": [
    "# 모델에 학습된 가중치를 업로드.\n",
    "weights = torch.load(f'test_percent_unit_{version}_{lr}_{epochs}_MAE.pth', map_location='cuda:1')\n",
    "#weights = torch.load(f'test_percent_unit_(23, 36)_0.001_100_MSE+MAE.pth', map_location='cuda:1')\n",
    "test_model.load_state_dict(weights)\n",
    "test_model = test_model.to(device)\n",
    "test_model.eval()\n",
    "test_time=time.time()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        outputs = test_model(data.float())\n",
    "    print('Test Time : ',time.time()-test_time)\n",
    "pred_test = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_layer=[[str(i) for i in np.arange(1000,8100,100).tolist()],[str(i) for i in np.arange(1000,8100,100).tolist()],['layer(nm)','level(%)']]\n",
    "test_layer=[[str(i) for i in wavenumbers.tolist()],[str(i) for i in wavenumbers.tolist()],['layer(nm)','level(%)']]\n",
    "test_layer=list(chain(*test_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pred_test.cpu().numpy()\n",
    "sub=pd.DataFrame(data=sub, columns=test_layer)\n",
    "sub.to_csv('weight_upper_result_UNet(weight).csv',index='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1020.0</th>\n",
       "      <th>1040.0</th>\n",
       "      <th>1060.0</th>\n",
       "      <th>1080.0</th>\n",
       "      <th>1100.0</th>\n",
       "      <th>1120.0</th>\n",
       "      <th>1140.0</th>\n",
       "      <th>1160.0</th>\n",
       "      <th>1180.0</th>\n",
       "      <th>...</th>\n",
       "      <th>5900.0</th>\n",
       "      <th>6200.0</th>\n",
       "      <th>6500.0</th>\n",
       "      <th>6800.0</th>\n",
       "      <th>7100.0</th>\n",
       "      <th>7400.0</th>\n",
       "      <th>7700.0</th>\n",
       "      <th>8000.0</th>\n",
       "      <th>layer(nm)</th>\n",
       "      <th>level(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.217420</td>\n",
       "      <td>2.337192</td>\n",
       "      <td>2.504164</td>\n",
       "      <td>2.767029</td>\n",
       "      <td>3.213556</td>\n",
       "      <td>4.865026</td>\n",
       "      <td>1.525314</td>\n",
       "      <td>0.929571</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.675197</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.546377e-07</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>271.227386</td>\n",
       "      <td>0.006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.377083</td>\n",
       "      <td>2.512094</td>\n",
       "      <td>2.697872</td>\n",
       "      <td>3.001064</td>\n",
       "      <td>3.526159</td>\n",
       "      <td>5.187152</td>\n",
       "      <td>1.641496</td>\n",
       "      <td>0.903489</td>\n",
       "      <td>0.922200</td>\n",
       "      <td>0.681825</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.441124e-05</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>271.427490</td>\n",
       "      <td>0.649024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.456431</td>\n",
       "      <td>2.596954</td>\n",
       "      <td>2.795885</td>\n",
       "      <td>3.116758</td>\n",
       "      <td>3.664362</td>\n",
       "      <td>5.102752</td>\n",
       "      <td>1.610471</td>\n",
       "      <td>0.864236</td>\n",
       "      <td>0.873421</td>\n",
       "      <td>0.657356</td>\n",
       "      <td>...</td>\n",
       "      <td>1.649195e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>254.559830</td>\n",
       "      <td>1.628768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.345692</td>\n",
       "      <td>2.475457</td>\n",
       "      <td>2.655842</td>\n",
       "      <td>2.947276</td>\n",
       "      <td>3.455750</td>\n",
       "      <td>5.058508</td>\n",
       "      <td>1.564708</td>\n",
       "      <td>0.905999</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>0.674646</td>\n",
       "      <td>...</td>\n",
       "      <td>1.714744e-05</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>255.111160</td>\n",
       "      <td>0.941806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.531913</td>\n",
       "      <td>2.683687</td>\n",
       "      <td>2.901067</td>\n",
       "      <td>3.253241</td>\n",
       "      <td>3.859861</td>\n",
       "      <td>5.188683</td>\n",
       "      <td>1.598520</td>\n",
       "      <td>0.815064</td>\n",
       "      <td>0.784694</td>\n",
       "      <td>0.535407</td>\n",
       "      <td>...</td>\n",
       "      <td>4.529405e-06</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>253.473373</td>\n",
       "      <td>1.998475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.455280</td>\n",
       "      <td>2.598201</td>\n",
       "      <td>2.802575</td>\n",
       "      <td>3.133687</td>\n",
       "      <td>3.722151</td>\n",
       "      <td>5.257517</td>\n",
       "      <td>1.524615</td>\n",
       "      <td>0.787010</td>\n",
       "      <td>0.764194</td>\n",
       "      <td>0.537101</td>\n",
       "      <td>...</td>\n",
       "      <td>7.469382e-07</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>256.997955</td>\n",
       "      <td>1.654577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1000.0    1020.0    1040.0    1060.0    1080.0    1100.0    1120.0  \\\n",
       "0  2.217420  2.337192  2.504164  2.767029  3.213556  4.865026  1.525314   \n",
       "1  2.377083  2.512094  2.697872  3.001064  3.526159  5.187152  1.641496   \n",
       "2  2.456431  2.596954  2.795885  3.116758  3.664362  5.102752  1.610471   \n",
       "3  2.345692  2.475457  2.655842  2.947276  3.455750  5.058508  1.564708   \n",
       "4  2.531913  2.683687  2.901067  3.253241  3.859861  5.188683  1.598520   \n",
       "5  2.455280  2.598201  2.802575  3.133687  3.722151  5.257517  1.524615   \n",
       "\n",
       "     1140.0    1160.0    1180.0  ...        5900.0    6200.0    6500.0  \\\n",
       "0  0.929571  0.964791  0.675197  ... -2.546377e-07  0.000031  0.000036   \n",
       "1  0.903489  0.922200  0.681825  ... -1.441124e-05  0.000032  0.000040   \n",
       "2  0.864236  0.873421  0.657356  ...  1.649195e-05  0.000038  0.000045   \n",
       "3  0.905999  0.920500  0.674646  ...  1.714744e-05  0.000036  0.000045   \n",
       "4  0.815064  0.784694  0.535407  ...  4.529405e-06  0.000040  0.000044   \n",
       "5  0.787010  0.764194  0.537101  ...  7.469382e-07  0.000037  0.000044   \n",
       "\n",
       "     6800.0    7100.0    7400.0    7700.0    8000.0   layer(nm)  level(%)  \n",
       "0  0.000037  0.000453  0.000006  0.000004  0.000005  271.227386  0.006592  \n",
       "1  0.000036  0.000350  0.000006  0.000006  0.000005  271.427490  0.649024  \n",
       "2  0.000038  0.000357  0.000006  0.000003  0.000005  254.559830  1.628768  \n",
       "3  0.000036  0.000391  0.000006  0.000004  0.000005  255.111160  0.941806  \n",
       "4  0.000038  0.000314  0.000006  0.000003  0.000005  253.473373  1.998475  \n",
       "5  0.000038  0.000346  0.000006  0.000003  0.000005  256.997955  1.654577  \n",
       "\n",
       "[6 rows x 144 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub #200102 12:21 두께만 안 맞음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1300</th>\n",
       "      <th>1400</th>\n",
       "      <th>1500</th>\n",
       "      <th>1600</th>\n",
       "      <th>1700</th>\n",
       "      <th>1800</th>\n",
       "      <th>1900</th>\n",
       "      <th>...</th>\n",
       "      <th>7100.2</th>\n",
       "      <th>7200.2</th>\n",
       "      <th>7300.2</th>\n",
       "      <th>7400.2</th>\n",
       "      <th>7500.2</th>\n",
       "      <th>7600.2</th>\n",
       "      <th>7700.2</th>\n",
       "      <th>7800.2</th>\n",
       "      <th>7900.2</th>\n",
       "      <th>8000.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146337</td>\n",
       "      <td>0.143524</td>\n",
       "      <td>0.140819</td>\n",
       "      <td>0.138209</td>\n",
       "      <td>0.135781</td>\n",
       "      <td>0.133682</td>\n",
       "      <td>0.131607</td>\n",
       "      <td>0.129836</td>\n",
       "      <td>0.128265</td>\n",
       "      <td>0.126791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166337</td>\n",
       "      <td>0.163524</td>\n",
       "      <td>0.160819</td>\n",
       "      <td>0.158209</td>\n",
       "      <td>0.155781</td>\n",
       "      <td>0.153682</td>\n",
       "      <td>0.151607</td>\n",
       "      <td>0.149836</td>\n",
       "      <td>0.148265</td>\n",
       "      <td>0.146791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186337</td>\n",
       "      <td>0.183524</td>\n",
       "      <td>0.180819</td>\n",
       "      <td>0.178209</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.173682</td>\n",
       "      <td>0.171607</td>\n",
       "      <td>0.169836</td>\n",
       "      <td>0.168265</td>\n",
       "      <td>0.166791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206337</td>\n",
       "      <td>0.203524</td>\n",
       "      <td>0.200819</td>\n",
       "      <td>0.198209</td>\n",
       "      <td>0.195781</td>\n",
       "      <td>0.193682</td>\n",
       "      <td>0.191607</td>\n",
       "      <td>0.189836</td>\n",
       "      <td>0.188265</td>\n",
       "      <td>0.186791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226337</td>\n",
       "      <td>0.223524</td>\n",
       "      <td>0.220819</td>\n",
       "      <td>0.218209</td>\n",
       "      <td>0.215781</td>\n",
       "      <td>0.213682</td>\n",
       "      <td>0.211607</td>\n",
       "      <td>0.209836</td>\n",
       "      <td>0.208265</td>\n",
       "      <td>0.206791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1000      1100      1200      1300      1400      1500      1600  \\\n",
       "0  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745   \n",
       "1  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745   \n",
       "2  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745   \n",
       "3  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745   \n",
       "4  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745  1.224745   \n",
       "\n",
       "       1700      1800      1900  ...    7100.2    7200.2    7300.2    7400.2  \\\n",
       "0  1.224745  1.224745  1.224745  ...  0.146337  0.143524  0.140819  0.138209   \n",
       "1  1.224745  1.224745  1.224745  ...  0.166337  0.163524  0.160819  0.158209   \n",
       "2  1.224745  1.224745  1.224745  ...  0.186337  0.183524  0.180819  0.178209   \n",
       "3  1.224745  1.224745  1.224745  ...  0.206337  0.203524  0.200819  0.198209   \n",
       "4  1.224745  1.224745  1.224745  ...  0.226337  0.223524  0.220819  0.218209   \n",
       "\n",
       "     7500.2    7600.2    7700.2    7800.2    7900.2    8000.2  \n",
       "0  0.135781  0.133682  0.131607  0.129836  0.128265  0.126791  \n",
       "1  0.155781  0.153682  0.151607  0.149836  0.148265  0.146791  \n",
       "2  0.175781  0.173682  0.171607  0.169836  0.168265  0.166791  \n",
       "3  0.195781  0.193682  0.191607  0.189836  0.188265  0.186791  \n",
       "4  0.215781  0.213682  0.211607  0.209836  0.208265  0.206791  \n",
       "\n",
       "[5 rows x 215 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.read_csv(path_train)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom=ConvNet()\n",
    "params = custom.state_dict()\n",
    "dummy_data = torch.empty(1, 71, dtype=torch.float32)\n",
    "torch.onnx.export(custom, dummy_data, 'Unet+FCN.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
